{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier's Initialization\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def initialize_parameters(network_structure):\n",
    "    \n",
    "    '''\n",
    "    Parametros de entrada:\n",
    "    network_structure: vector que describe la estructura de\n",
    "                       la red neuronal de la siguiente manera:\n",
    "                       \n",
    "                       primera posición: numero de entradas de la red neuronal (para este ejemplo será de 12288)\n",
    "                       ultima posición: capa de salida (para este ejemplo será  1)\n",
    "                       posiciones intermedias: cada posicion es una capa oculta y el valor indica cuantas\n",
    "                                               neuronas componen cada capa\n",
    "  \n",
    "    Retorna un arreglo con dos diccionarios, en la primera posición esta W y en la segunda esta b  \n",
    "    '''    \n",
    "\n",
    "    parametersW={}\n",
    "    parametersb={}\n",
    "    \n",
    "    for i in range(1, len(network_structure)): #Ciclo que inicializa los parametros W y b de la red neuronal\n",
    "        W = np.random.randn(network_structure[i], network_structure[i-1]) * np.sqrt(2./float(network_structure[i-1] + network_structure[i]))\n",
    "        b = np.zeros([network_structure[i], 1])\n",
    "        parametersW[\"W\" + str(i)] = W\n",
    "        parametersb[\"b\" + str(i)] = b\n",
    "\n",
    "    return parametersW, parametersb\n",
    "\n",
    "def linear_activation(W, b, X):\n",
    "    '''\n",
    "    Returns linear activation for W, b and X\n",
    "    '''\n",
    "    z = np.dot(W, X) + b    \n",
    "    return z\n",
    "\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    Returns sigmoid activation for array z\n",
    "    '''\n",
    "    a = 1. / (1. + np.exp(-z)) \n",
    "    \n",
    "    return a \n",
    "\n",
    "def tanh(z):\n",
    "    '''\n",
    "    Returns hiperbolic tangent activation for array z\n",
    "    '''\n",
    "    a = (np.exp(z)- np.exp(-z))/(np.exp(z)+ np.exp(-z))\n",
    "    return a\n",
    "\n",
    "\n",
    "def forward_propagation(parametersW, parametersb, activate_functions, X):\n",
    "    \n",
    "    '''\n",
    "    Parametros de entrada:\n",
    "    \n",
    "    Esta funcion recibe 4 parametros de entrada los cuales constan de:\n",
    "    \n",
    "    paremetersW: es un diccionario que contiene todos los parametros de inicialización de W  de la red neuronal\n",
    "                esta almacenado en la posición 0 del arreglo que retorna la funcion initialize_parameters\n",
    "                \n",
    "    paremetersb: es un diccionario que contiene todos los parametros de inicialización de b  de la red neuronal\n",
    "                esta almacenado en la posición 1 del arreglo que retorna la funcion initialize_parameters    \n",
    "    \n",
    "    activate_functions: es un vector de caracteres que determina, para cada capa, cual es su funcion de activacion\n",
    "                        su estructura es la siguiente:\n",
    "                        su tamaño debe coincidir con el numero de componentes del diccionario W o diccionario b\n",
    "                        cada posicion del vector sera una letra mayuscula (S para sigmoide, T para tangente hiperbolica)\n",
    "                        la ultima capa, para este ejemplo siempre será una funcion de activación sigmoide\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    layers = len(parametersW)\n",
    "    number_of_activate_functions = len(activate_functions)    \n",
    "    resultsA={}\n",
    "    resultsZ={}\n",
    "    \n",
    "\n",
    "    \n",
    "    if (layers != number_of_activate_functions): #se verifica que cada capa tenga su funcion de activacion\n",
    "        print \"hiden layers and activate functions don't match\"\n",
    "        return 0    \n",
    "    \n",
    "    for i in range(layers):\n",
    "        if (i==0):\n",
    "            Z = linear_activation(parametersW[\"W\"+str(i+1)], parametersb[\"b\"+str(i+1)], X)\n",
    "            resultsZ[\"Z\" + str(i+1)] = Z\n",
    "        else:\n",
    "            Z = linear_activation(parametersW[\"W\"+str(i+1)], parametersb[\"b\"+str(i+1)],  resultsZ[\"Z\" + str(i)])\n",
    "            resultsZ[\"Z\" + str(i+1)] = Z\n",
    "        if (activate_functions[i] == \"S\"):\n",
    "            A = sigmoid(Z)\n",
    "            resultsA[\"A\" + str(i+1)] = A\n",
    "        elif (activate_functions[i] == \"T\"):\n",
    "            A = tanh(Z)\n",
    "            resultsA[\"A\" + str(i+1)] = A\n",
    "     \n",
    "    \n",
    "    return resultsZ, resultsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'W3': array([[-0.37628328, -0.43167428,  0.28596595]]), 'W2': array([[-0.9397524 , -0.00410522],\n",
      "       [-0.21589459,  1.01616539],\n",
      "       [-0.3117487 ,  0.35241137]]), 'W1': array([[ 0.01251963,  0.02245265,  0.01396418, ...,  0.01141745,\n",
      "         0.01260991,  0.01470833],\n",
      "       [-0.00296206, -0.00789279, -0.02148552, ..., -0.01272004,\n",
      "         0.00249015, -0.00071411]])}, {'b1': array([[ 0.],\n",
      "       [ 0.]]), 'b2': array([[ 0.],\n",
      "       [ 0.],\n",
      "       [ 0.]]), 'b3': array([[ 0.]])})\n",
      "({'Z1': array([[ 1.06600517],\n",
      "       [-0.97645576]]), 'Z2': array([[-0.99777235],\n",
      "       [-1.22238529],\n",
      "       [-0.67643984]]), 'Z3': array([[ 0.70967858]])}, {'A1': array([[ 0.74383647],\n",
      "       [ 0.27359561]]), 'A3': array([[ 0.67033013]]), 'A2': array([[-0.76065701],\n",
      "       [-0.84035638],\n",
      "       [-0.58920004]])})\n"
     ]
    }
   ],
   "source": [
    "Red_Neuronal = np.array([12288,2,3,1])\n",
    "Funciones_Activacion = np.array([\"S\",\"T\",\"S\"])\n",
    "X = np.random.rand(12288,1)\n",
    "\n",
    "parameters = initialize_parameters(Red_Neuronal)\n",
    "fw_prop = forward_propagation(parameters[0], parameters[1],Funciones_Activacion,X)\n",
    "\n",
    "print parameters\n",
    "print fw_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initialize_parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
